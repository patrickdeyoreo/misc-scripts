#!/usr/bin/env python3
"""
Find duplicate files
"""

from argparse import Action, ArgumentParser
from hashlib import md5
from os import listdir, path
from shlex import quote
from sys import argv, stderr


class AccumulateFiles(Action):
    """
    Construct a list of filenames from a list of paths
    """
    def __call__(self, parser, namespace, values, option_string=None):
        """
        Store a list of filenames in the dest associated with this Action
        """
        if getattr(namespace, self.dest) is None:
            setattr(namespace, self.dest, [])
        files = getattr(namespace, self.dest)
        for name in values:
            if path.isdir(name):
                for name in type(self).listdir(name):
                    if path.isdir(name):
                        if getattr(namespace, "recursive") is True:
                            type(self).recursedir(files, name)
                    else:
                        files.append(name)
            elif path.exists(name):
                files.append(name)
            else:
                raise FileNotFoundError(name)

    @staticmethod
    def recursedir(files, dirname):
        """
        Extend files with the contents of directory and its subdirectories
        """
        for name in type(self).listdir(dirname):
            if path.isdir(name):
                type(self).recursedir(files, name)
            else:
                files.append(name)

    @staticmethod
    def listdir(dirname):
        """
        Retrieve a list of paths to all files in a directory
        """
        return [path.join(dirname, name) for name in listdir(dirname)]


if __name__ == "__main__":

    parser = ArgumentParser(prog=path.basename(argv[0]))

    parser.add_argument("-r", "--recursive",
                        action="store_true",
                        help="operate recursively on directories")
    parser.add_argument("-v", "--verbose",
                        action="store_true",
                        help="print the name of each file as it's checked")
    parser.add_argument("files",
                        nargs="+",
                        action=AccumulateFiles,
                        help="files and directories to check for duplicates")

    args = parser.parse_args()
    args.files.sort()
    dups = set()
    sums = {}

    for name in args.files:
        md5sum = md5()
        try:
            with open(name, "rb") as istream:
                md5sum.update(istream.read())
        except FileNotFoundError:
            print(f"File Not Found: {quote(name)}", file=stderr)
        else:
            if getattr(args, "verbose") is True:
                print(f"[{md5sum.hexdigest()}] {quote(name)}", file=stderr)
            if md5sum.digest() in sums:
                dups.add(md5sum.digest())
                sums[md5sum.digest()].append(name)
            else:
                sums[md5sum.digest()] = [name]

    for digest in dups:
        print(f"-- {digest.hex()} --")
        print(*map(quote, sums[digest]), sep="\n")
